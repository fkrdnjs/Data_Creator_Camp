{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21332,"status":"ok","timestamp":1698947978992,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"Ozmwes1wIQsx","outputId":"01e534fd-682a-40db-f51f-928fc43386f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3735,"status":"ok","timestamp":1698948115611,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"4Dp35RHdMrDc"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import models\n","import os\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698948115612,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"7i8paMzmMw0s"},"outputs":[],"source":["# 1. 데이터셋 경로 설정\n","train_dir = '/content/drive/MyDrive/kfood_health_train'\n","val_dir = '/content/drive/MyDrive/kfood_health_val'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":29057,"status":"ok","timestamp":1698948156755,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"G_H1kR6sM2ET"},"outputs":[],"source":["# 2. 데이터 전처리 설정\n","class Cutout(object):\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = int(np.clip(y - self.length // 2, 0, h))\n","            y2 = int(np.clip(y + self.length // 2, 0, h))\n","            x1 = int(np.clip(x - self.length // 2, 0, w))\n","            x2 = int(np.clip(x + self.length // 2, 0, w))\n","\n","            mask[y1: y2,x1: x2] = 0.\n","\n","        mask=torch.from_numpy(mask)\n","        mask=mask.expand_as(img)\n","\n","        return img*mask\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Training data augmentation\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),  # Random resize and crop to 224x224\n","    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n","    transforms.RandomRotation(degrees=15), # 회전 추가\n","    transforms.ToTensor(),  # Convert image to a PyTorch tensor\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n","    Cutout(n_holes=1,length=16) # 노이즈 추가\n","])\n","\n","# Validation: only normalization (and potentially resizing)\n","val_transform = transforms.Compose([\n","    transforms.Resize(256),  # Resize to 256x256\n","    transforms.CenterCrop(224),  # Crop to 224x224 around the center\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_dataset = torchvision.datasets.ImageFolder(root=train_dir, transform=train_transform)\n","val_dataset = torchvision.datasets.ImageFolder(root=val_dir, transform=val_transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10084,"status":"ok","timestamp":1698948174700,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"hSTmc7JiXs8O","outputId":"8899eb01-4850-4a12-8e63-081f9f6260ab"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=13, bias=True)\n",")"]},"metadata":{},"execution_count":5}],"source":["# 3. 모델 불러오기 및 수정\n","model = models.resnet50(pretrained=False)\n","\n","# 체크포인트 불러오기\n","checkpoint = torch.load('/content/drive/MyDrive/model_checkpoint_resnet50_fin.pth', map_location='cpu')\n","\n","# 마지막 계층 변경\n","# 원래 체크포인트 모델의 'fc' 계층을 새로운 클래스 수에 맞는 계층으로 변경\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 13)\n","\n","# 'fc' 계층의 가중치를 제외하고 모델에 로드\n","model_dict = model.state_dict()\n","checkpoint_dict = {k: v for k, v in checkpoint['model_state_dict'].items() if k in model_dict and model_dict[k].shape == checkpoint['model_state_dict'][k].shape}\n","model_dict.update(checkpoint_dict)\n","model.load_state_dict(model_dict)\n","\n","# GPU 사용 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698948178791,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"WC3W2-6JG6PC","outputId":"791c6b16-a901-4f74-a21a-8ef623f1f0a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({10: 1551, 1: 1267, 3: 1237, 2: 1177, 8: 1160, 12: 1152, 9: 1040, 4: 1032, 7: 962, 6: 951, 5: 891, 11: 864, 0: 831})\n"]}],"source":["# 손실함수와 최적화 함수 설정\n","from collections import Counter\n","from torch import optim\n","\n","# 각 클래스별 이미지의 개수 계산\n","class_counts = Counter(train_dataset.targets)\n","\n","print(class_counts)\n","\n","# class_counts를 리스트로 변환\n","class_counts = [class_counts[i] for i in range(len(class_counts))]\n","total_size = sum(class_counts)  # 전체 크기를 계산\n","\n","class_weights = [total_size / count for count in class_counts]\n","class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n","criterion = nn.CrossEntropyLoss(weight=class_weights)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7829,"status":"ok","timestamp":1698948190451,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"ISAJ9uF1bnE1","outputId":"cd042686-c93d-4216-b237-a6ab635f86aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl (243 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=9c973d47305c20c82ee461fe5ca4214ec78ea7e250d0500f8201d51c16da6f6b\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 pathtools-0.1.2 sentry-sdk-1.34.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.15.12\n"]}],"source":["!pip install wandb --upgrade"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19399,"status":"ok","timestamp":1698948209844,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"zfeIBaS2bn4r","outputId":"f5dbc31e-88f8-4f3d-9b2d-067d81ed9706"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["import wandb\n","\n","!wandb login"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698948213830,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"7MbIoIuPbs9l"},"outputs":[],"source":["import os\n","os.environ[\"WANDB_START_METHOD\"] = \"thread\""]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":5697,"status":"ok","timestamp":1698948248832,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"5A3mIgCdbrgN","outputId":"3ace0f78-db0c-480e-c465-3926d5d9ca15"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeuldeulkang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.12"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20231102_180406-fg71bcwh</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/deuldeulkang/M3_res50_weight_trans/runs/fg71bcwh' target=\"_blank\">M3_res50_weight_trans</a></strong> to <a href='https://wandb.ai/deuldeulkang/M3_res50_weight_trans' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/deuldeulkang/M3_res50_weight_trans' target=\"_blank\">https://wandb.ai/deuldeulkang/M3_res50_weight_trans</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/deuldeulkang/M3_res50_weight_trans/runs/fg71bcwh' target=\"_blank\">https://wandb.ai/deuldeulkang/M3_res50_weight_trans/runs/fg71bcwh</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":10}],"source":["# Wandb 실험 초기화\n","wandb.init(project='M3_res50_weight_trans', entity='deuldeulkang',name='M3_res50_weight_trans')  # 프로젝트와 사용자 이름을 꼭 바꿔주세요!\n","# Wandb 설정 저장\n","\n","wandb.config = {\n","  \"learning_rate\": 0.001,\n","  \"epochs\": 30,\n","  \"batch_size\": 64\n","}\n","wandb.watch(model)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1698948255874,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"mnXCV7UJauMd"},"outputs":[],"source":["from tqdm import tqdm\n","\n","# 5. 학습 및 검증 함수 정의\n","def train(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","\n","    return running_loss / len(train_loader.dataset)\n","\n","def validate(model, val_loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    correct_predictions = 0\n","    total_predictions = 0\n","    with torch.no_grad():\n","        for inputs, labels in tqdm(val_loader, desc=\"Validating\"):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct_predictions += (preds == labels).sum().item()\n","            total_predictions += labels.size(0)\n","\n","    average_loss = running_loss / len(val_loader.dataset)\n","    accuracy = (correct_predictions / total_predictions) * 100\n","    return average_loss, accuracy\n"]},{"cell_type":"markdown","metadata":{"id":"jb6OT-VSkjnN"},"source":["- 체크포인트 불러오는거 필요한 것만 불러오게 수정한 다음에 써야할듯"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1180,"status":"ok","timestamp":1698948299909,"user":{"displayName":"강들들","userId":"14569399971279826247"},"user_tz":-540},"id":"Oe6MVd-icCWU","outputId":"2935d5d2-85bf-4afe-bf38-0c3b56da1638"},"outputs":[{"output_type":"stream","name":"stdout","text":["No checkpoint file found, starting training from scratch.\n"]}],"source":["# 모델 로드와 학습 재개\n","start_epoch = 0  # 시작 에포크 초기값 설정\n","best_acc = 0.0  # 최고 정확도 초기값 설정\n","save_path = \"/content/drive/MyDrive/Mission3_res50_weight_trans.pt\"\n","\n","# 체크포인트 파일이 존재하는지 확인 후, 로드\n","try:\n","    checkpoint = torch.load(save_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    start_epoch = checkpoint['epoch']\n","    best_acc = checkpoint['best_acc']\n","    print(f\"Loaded checkpoint from epoch {start_epoch}, best accuracy was {best_acc:.2f}%\")\n","except FileNotFoundError:\n","    print(\"No checkpoint file found, starting training from scratch.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_g6KzOIaxgM","outputId":"873e7994-4c7b-457b-84f7-fc6a66f6757e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [43:14<00:00, 11.74s/it]\n","Validating: 100%|██████████| 28/28 [05:30<00:00, 11.79s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30 - Train Loss: 0.6892 - Val Loss: 0.2954 - Val Acc: 88.95%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:58<00:00,  1.24it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/30 - Train Loss: 0.3904 - Val Loss: 0.1890 - Val Acc: 93.37%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:56<00:00,  1.25it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/30 - Train Loss: 0.3123 - Val Loss: 0.1431 - Val Acc: 94.73%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:58<00:00,  1.24it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/30 - Train Loss: 0.2791 - Val Loss: 0.1151 - Val Acc: 95.01%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:57<00:00,  1.24it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/30 - Train Loss: 0.2460 - Val Loss: 0.0909 - Val Acc: 95.69%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:55<00:00,  1.26it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/30 - Train Loss: 0.2422 - Val Loss: 0.0956 - Val Acc: 95.80%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [03:00<00:00,  1.23it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.09s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/30 - Train Loss: 0.2103 - Val Loss: 0.0993 - Val Acc: 95.80%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [03:01<00:00,  1.22it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/30 - Train Loss: 0.2204 - Val Loss: 0.0857 - Val Acc: 96.26%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [03:03<00:00,  1.21it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/30 - Train Loss: 0.1997 - Val Loss: 0.0602 - Val Acc: 97.11%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:59<00:00,  1.23it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/30 - Train Loss: 0.2050 - Val Loss: 0.0613 - Val Acc: 96.60%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [03:00<00:00,  1.22it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/30 - Train Loss: 0.1788 - Val Loss: 0.0588 - Val Acc: 97.39%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [03:01<00:00,  1.22it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.09s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/30 - Train Loss: 0.1767 - Val Loss: 0.0567 - Val Acc: 97.45%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [03:03<00:00,  1.20it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/30 - Train Loss: 0.1684 - Val Loss: 0.0594 - Val Acc: 97.22%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [03:05<00:00,  1.19it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/30 - Train Loss: 0.1627 - Val Loss: 0.0561 - Val Acc: 97.05%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [03:01<00:00,  1.22it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/30 - Train Loss: 0.1679 - Val Loss: 0.0467 - Val Acc: 97.85%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:58<00:00,  1.24it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/30 - Train Loss: 0.1670 - Val Loss: 0.0596 - Val Acc: 97.45%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:57<00:00,  1.24it/s]\n","Validating: 100%|██████████| 28/28 [00:30<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/30 - Train Loss: 0.1485 - Val Loss: 0.0487 - Val Acc: 97.56%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:57<00:00,  1.24it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/30 - Train Loss: 0.1588 - Val Loss: 0.0451 - Val Acc: 97.51%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:55<00:00,  1.26it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/30 - Train Loss: 0.1481 - Val Loss: 0.0492 - Val Acc: 97.39%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:56<00:00,  1.25it/s]\n","Validating: 100%|██████████| 28/28 [00:29<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/30 - Train Loss: 0.1455 - Val Loss: 0.0455 - Val Acc: 97.51%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:54<00:00,  1.27it/s]\n","Validating: 100%|██████████| 28/28 [00:28<00:00,  1.03s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/30 - Train Loss: 0.1439 - Val Loss: 0.0708 - Val Acc: 96.77%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 221/221 [02:52<00:00,  1.28it/s]\n","Validating: 100%|██████████| 28/28 [00:28<00:00,  1.03s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/30 - Train Loss: 0.1412 - Val Loss: 0.0489 - Val Acc: 97.17%\n"]},{"output_type":"stream","name":"stderr","text":["Training:  59%|█████▉    | 130/221 [01:43<01:10,  1.30it/s]"]}],"source":["# 6. 학습 시작\n","num_epochs = 30\n","best_acc = 0.0\n","for epoch in range(start_epoch, num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    val_loss, val_acc = validate(model, val_loader, criterion, device)\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.2f}%\")\n","\n","    wandb.log({\n","         \"Epoch\": epoch,\n","         \"Train Loss\": train_loss,\n","         \"Validation Loss\": val_loss,\n","         \"Validation Accuracy\": val_acc\n","\n","    })\n","\n","    if val_acc > best_acc:\n","        best_acc = val_acc\n","        torch.save({\n","            'epoch': epoch + 1,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'best_acc': best_acc,\n","        }, '/content/drive/MyDrive/Mission3_res50_weight_trans.pt')\n","\n","wandb.finish()\n","\n","print(\"Training Complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLN3tfeYcszi"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}